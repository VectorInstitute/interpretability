# Interpretable and Explainable AI Bootcamp

This is the official repository for the 2025 Bootcamp on Interpretable and Explainable AI by Vector Institute. All reference implementations are present in `implementations` folder. Small datasets are present in the corresponding subfolders, and the large datasets are present on the cluster at `/ssd003/projects/aieng/public/interp_bootcamp/datasets`.

## Repository Structure

- [implementations](https://github.com/VectorInstitute/interpretability-bootcamp/tree/main/implementations) folder contains all the code covered in this bootcamp, and is organized by topic. Each topic has its own directory containing python scripts, notebooks, datasets and a README for guidance.
- [scripts](https://github.com/VectorInstitute/interpretability-bootcamp/tree/main/scripts) contains utility scripts for submiting training jobs.
- [pyproject.toml](https://github.com/VectorInstitute/interpretability-bootcamp/blob/main/pyproject.toml) file configures various build system requirements and dependencies, centralizing project settings in a standardized format.
- [requirements.txt](https://github.com/VectorInstitute/interpretability-bootcamp/blob/main/requirements.txt) file contains a list of packages and their versions required to run the implementations. This can be used to setup your own environment in the cluster/your machine.
- [uv.lock](https://github.com/VectorInstitute/interpretability-bootcamp/blob/main/uv.lock) file contains list of project dependencies generated by uv.

## Bootcamp Content

Each topic within the bootcamp has a dedicated directory in the `implementations/` folder. In each directory, there is a `README.md` file that provides an overview of the topic, prerequisites, and notebook descriptions.

Here is the list of topics covered in this bootcamp:

- Post-hoc Explainability Methods in [Post-hoc](https://github.com/VectorInstitute/interpretability-bootcamp/tree/main/implementations/Post-hoc):
    - LIME
    - SHAP
    - PDP
    - ALE
    - Integrated Gradients
    - Counterfactual Explanations

- Interpretable models in [Interpretable-models](https://github.com/VectorInstitute/interpretability-bootcamp/tree/main/implementations/Intepretable-models):
    - GAM
    - NAM
    - EBM
    - GOSDT/GHOUL
    - COXNAM
    - NBM
    - ProtoPNet
    - TabNet
    - Self Attention
    - B-COS Networks

## Getting Started

Please check the following requirements before running the code examples on your cluster.

### Prerequisites

1. A Github account with security credentials setup to clone the repository.
2. Access to the Vector Institute's cluster: You will be able to login via `ssh username@v.vectorinstitute.ai` and 2FA via mobile authentication.
3. VPN setup via Fortinet client: After connecting via VPN, you will be able to login to the Jupyter Hub server hosted at https://vdm1.cluster.local:8000/.

### Python Version
Check this if you are running the code on your laptop.

- Python >= 3.10


### Resources

1. As a part of your cluster account, you have been allocated a scratch folder where code, checkpoints and training artifacts can be stored. It is at the location
```bash
/scratch/ssd004/scratch/<username>
```
It can also be a different path with `ssd003`.

2. A virtual environment is present at a shard location on the cluster. Please source it using the following command:
```bash
source /ssd003/projects/aieng/public/interp_bootcamp/venv/bin/activate
```
3. Large datasets used within the repository are present at the location `/ssd003/projects/aieng/public/interp_bootcamp/datasets`.
4. Pretrained models are available at the location `/ssd003/projects/aieng/public/interp_bootcamp/checkpoints`.

>[!NOTE]
>- If you face any issues with the pre-requisites or are unable to access any of the cluster resources, please contact your facilitator.

## Running the code

Please follow the steps in [instructions.md](instructions.md) to run the examples in this repository.
Please follow steps in [scripts.md](scripts/scripts.md) to run slurm scripts.

## License
This project is licensed under the terms of the [LICENSE.md](LICENSE.md) file located in the root directory of this repository.

## Contribution
To get started with contributing to our project, please read our [CONTRIBUTING.md](CONTRIBUTING.md) guide.

## Contact Information

For more information or help with navigating this repository, please contact Dhanesh Ramachandram, Applied ML Scientist, Health Lead at [dhanesh.ramachandram@vectorinstitute.ai] or Ananya Raval, Software Developer, AI Eng. [ananya.raval@vectorinstitute.ai]
