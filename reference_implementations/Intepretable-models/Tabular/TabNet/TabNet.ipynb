{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tabular Network (TabNet)\n",
        "\n",
        "Explainable Boosting Machines (EBMs) are tree-based models mainly used for processing tabular data. These inherently interpretable algorithms are a subset of Generalized Additive Models (GAMs), which can be as accurate as black-box models, e.g., XGBoost. [1] For more information, you can refer to [this link](https://interpret.ml/docs/ebm.html)."
      ],
      "metadata": {
        "id": "8q01uTXSZqlf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "# from new_data import process_csv\n",
        "import sklearn\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import os\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.feature_selection import RFE\n",
        "from interpret.glassbox import ExplainableBoostingClassifier,merge_ebms\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.linear_model import LogisticRegression, Lasso, Ridge\n",
        "import pickle\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "Aix1VDGVZ2Mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data\n",
        "The dataset used in this notebook is US-130, which contains different  clinical measurements related to patients diagnosed with diabetes from 1999-2008. To find more information about this dataset, you can refer to [this link](https://archive.ics.uci.edu/dataset/296/diabetes+130-us+hospitals+for+years+1999-2008)."
      ],
      "metadata": {
        "id": "Or3v3kRAoL3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_csv(df):\n",
        "\n",
        "\n",
        "    df[\"readmitted_binarized\"] = df[\"readmitted\"].apply(lambda x: 1 if x==\"b'<30'\" else 0)\n",
        "    # dropping useless columns\n",
        "    df = df.drop(['Unnamed: 0',\"encounter_id\",\"patient_nbr\",\"examide\", \"readmitted\",\"weight\",\"payer_code\",\"medical_specialty\"], axis=1)\n",
        "\n",
        "\n",
        "    # # age transformation was extracted from: https://medium.com/analytics-vidhya/diabetes-130-us-hospitals-for-years-1999-2008-e18d69beea4d\n",
        "    age_dic = {\"b'[0-10)'\" : 5,\n",
        "    \"b'[10-20)'\" : 15,\n",
        "    \"b'[20-30)'\" : 25,\n",
        "    \"b'[30-40)'\" : 35,\n",
        "    \"b'[40-50)'\" : 45,\n",
        "    \"b'[50-60)'\" : 55,\n",
        "    \"b'[60-70)'\" : 65,\n",
        "    \"b'[70-80)'\" : 75,\n",
        "    \"b'[80-90)'\" : 85,\n",
        "    \"b'[90-100)'\" : 95}\n",
        "\n",
        "    df['age'] = df['age'].apply(lambda x : age_dic[x])\n",
        "\n",
        "    df[\"diag_1\"] = df[\"diag_1\"].apply(lambda x: x[:x.find(\".\")])\n",
        "    df[\"diag_2\"] = df[\"diag_2\"].apply(lambda x: x[:x.find(\".\")])\n",
        "    df[\"diag_3\"] = df[\"diag_3\"].apply(lambda x: x[:x.find(\".\")])\n",
        "\n",
        "    categorical_columns = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "    # https://www.kaggle.com/code/paulo100/tabtransformer-pytorch-dnn-with-attention-eda\n",
        "    threshold = 3\n",
        "    for col in df.columns:\n",
        "        if df[col].nunique() < threshold and col not in categorical_columns:\n",
        "            categorical_columns.append(col)\n",
        "\n",
        "    for cat_column in categorical_columns:\n",
        "      frequency_encoding = df[cat_column].value_counts(normalize=True).to_dict()\n",
        "      df[f\"encoded_{cat_column}\"] = df[cat_column].map(frequency_encoding)\n",
        "      df = df.drop(cat_column, axis=1)\n",
        "\n",
        "\n",
        "    categorical_columns = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "    numerical_columns = [col for col in df.columns if col not in categorical_columns]\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "xvewqs10Z4pR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data loading and preparation\n",
        "data = pd.read_csv(\"/Users/ananyaraval/workspace/interpretability-bootcamp/data/US_130/diabetic_data.csv\")\n",
        "df = process_csv(data)\n",
        "df.index=range(df.shape[0])\n",
        "    # categorical_columns = df.select_dtypes(include=['object', 'category']).columns\n",
        "X , y = df.drop(\"readmitted_binarized\",axis=1) , df[\"readmitted_binarized\"]\n",
        "    # embedded_cols = {n: len(col.cat.categories) for n,col in X[categorical_columns].items() if len(col.cat.categories) > 2}\n",
        "    # embedded_col_names = embedded_cols.keys()\n",
        "    # embedding_sizes = [(n_categories, min(50, (n_categories+1)//2)) for _,n_categories in embedded_cols.items()]\n",
        "k = 5\n",
        "indices = np.arange(len(X))\n",
        "np.random.shuffle(indices)\n",
        "folds = np.array_split(indices, k)\n"
      ],
      "metadata": {
        "id": "EH9zXc8yZ4tn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "atQ-hc2FZ4wi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = TabNetClassifier()\n",
        "\n",
        "        clf.fit(\n",
        "X_train.values, y_train.values,max_epochs=20\n",
        "# eval_set=[(X_test, y_test)]\n",
        ")\n",
        "y_pred = clf.predict(X_test.values)\n",
        "\n",
        "y_prob = clf.predict_proba(X_test.values)[:,1]\n",
        "\n",
        "val_auc = roc_auc_score(y_test, y_prob)\n",
        "val_f1 = f1_score(y_test,y_pred)\n",
        "val_precision = precision_score(y_test,y_pred)\n",
        "val_recall = recall_score(y_test,y_pred)\n",
        "print(\"val_auc\",val_auc)\n",
        "\n",
        "print(\"val_f1\",val_f1)\n",
        "print(\"val_precision\",val_precision)\n",
        "print(\"val_recall\",val_recall)"
      ],
      "metadata": {
        "id": "8zo0TjI4Z4zY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Global and Local Explainability:\n",
        "\n",
        "Global explainability refers to the features important to the whole model, while local explainability demonstrates the features determining in a specific prediction for a datapoint.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QngOy94rs0W_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# global explainabilit\n",
        "clf.feature_importances_"
      ],
      "metadata": {
        "id": "MfOsb6hOZ42Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As can be observed"
      ],
      "metadata": {
        "id": "38xqvS2kpUjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# local explainability\n",
        "explain_matrix, masks = clf.explain(X_test)"
      ],
      "metadata": {
        "id": "hBSxkEElZ45U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "06cf3cb6-6b03-4bd4-b7fb-eda97447424d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'clf' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f19f14abd859>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# local explainability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mexplain_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# visulaizing the local feature importance\n",
        "fig, axs = plt.subplots(1, 3, figsize=(20,20))\n",
        "\n",
        "for i in range(3):\n",
        "    axs[i].imshow(masks[i][:50])\n",
        "    axs[i].set_title(f\"mask {i}\")"
      ],
      "metadata": {
        "id": "txrFzqkDZ47-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uKpec8raZ4_H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}