{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrated Gradients to explain DNN Models on Tabular Data\n",
    "\n",
    "\n",
    "This example illustrates the use of Integrated Gradients on Tabular Data. \n",
    "**Integrated Gradients** is an attribution method designed to explain the predictions of deep neural networks by assigning an importance score to each input feature. In other words, it helps answer the question: “How much did each feature contribute to this prediction?”\n",
    "\n",
    "### Basic Idea: \n",
    " We measure the cumulative effect of each input feature by \"integrating\" the gradients of the model's output  w.r.t the input along the path of some baseline (usually one that represents absence of features). \n",
    "\n",
    " Definition of IG:\n",
    "\n",
    "Let:\n",
    "-\t F: $\\mathbb{R}^n \\rightarrow \\mathbb{R}$  be the model (typically a deep neural network) that produces a prediction.\n",
    "-\t $x \\in \\mathbb{R}^n$  be the actual input.\n",
    "-\t $x^{\\prime} \\in \\mathbb{R}^n$  be a baseline input (e.g., a vector of zeros or some neutral reference point).\n",
    "\n",
    "The integrated gradient for the i-th input feature is defined as:\n",
    "\n",
    " $$\n",
    "\\text{IG}_i(x) = (x_i - x'_i) \\times \\int_{0}^{1} \\frac{\\partial F\\big(x' + \\alpha (x - x')\\big)}{\\partial x_i} \\, d\\alpha\n",
    "$$\n",
    "\n",
    "In this example, we'll use integrated gradients as provided by the Captum library for PyTorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from os import path \n",
    "\n",
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "\n",
    "torch.manual_seed(34)\n",
    "np.random.seed(34)\n",
    "\n",
    "# uncomment this code to check if GPU is available\n",
    "'''\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=device)\n",
    "    print (x)\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    x = torch.ones(1, device=device)\n",
    "else:\n",
    "    print (\"GPU device not found.\")\n",
    "    device = torch.device(\"cpu\")\n",
    "'''    \n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Load the Portuguese bank dataset**\n",
    "\n",
    "- We will use the Portuguese bank dataset that we used for the Accumulated Local Effects (ALE) example. \n",
    "- To recap,these are 16 direct marketing (phone calls related) features from 45,211 clients and task is to  classify if client will subscribe a term deposit or not. \n",
    "- Dataset URL:  https://archive.ics.uci.edu/static/public/222/bank+marketing.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../acc_local_effects/datasets/bank-full.csv', delimiter=';')   \n",
    "display(df.head())\n",
    "print(df.shape)\n",
    "print(df['y'].value_counts()) # let's see if there is data imbalance in the target variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.Preprocess data and create Pytorch tensors**\n",
    "\n",
    "We have categorical features and numerical features. we transform categorical features to on-hot encoding and numerical features are scaled accordingly. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Automatically determine categorical and numerical features\n",
    "categorical_features = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "numerical_features = df.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "\n",
    "print(\"Categorical Features:\", categorical_features)\n",
    "print(\"Numerical Features:\", numerical_features)\n",
    "\n",
    "\n",
    "# Remove the target variable (if included in the dataset)\n",
    "target_variable = \"y\"\n",
    "if target_variable in categorical_features:\n",
    "    categorical_features.remove(target_variable)\n",
    "if target_variable in numerical_features:\n",
    "    numerical_features.remove(target_variable)\n",
    "    \n",
    "# Define the ColumnTransformer\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", scaler, numerical_features),   # Scale numerical features\n",
    "        (\"cat\", one_hot_encoder, categorical_features)  # One-hot encode categorical features\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(target_variable, axis=1)\n",
    "y = df[target_variable]\n",
    "\n",
    "# Convert true labels to binary format\n",
    "y= (y == 'yes').astype(int)\n",
    "\n",
    "# Apply the transformation to features\n",
    "processed_X = preprocessor.fit_transform(X)\n",
    "\n",
    "# Extract the fitted OneHotEncoder\n",
    "one_hot_encoder = preprocessor.named_transformers_[\"cat\"]\n",
    "\n",
    "# Get one-hot encoded column names\n",
    "one_hot_encoded_columns = one_hot_encoder.get_feature_names_out(categorical_features)\n",
    "\n",
    "# Combine with scaled numerical column names\n",
    "final_column_names = numerical_features + list(one_hot_encoded_columns)\n",
    "print(final_column_names)\n",
    "\n",
    "# Create a DataFrame with the transformed data\n",
    "processed_X_df = pd.DataFrame(processed_X, columns=final_column_names)\n",
    "\n",
    "# Display the DataFrame\n",
    "display(processed_X_df.head())\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(processed_X_df, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "X_train = torch.tensor(X_train.values).float()\n",
    "y_train = torch.tensor(y_train.values).view(-1, 1).float()\n",
    "\n",
    "X_test = torch.tensor(X_test.values).float()\n",
    "y_test = torch.tensor(y_test.values).view(-1, 1).float()\n",
    "\n",
    "datasets = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "train_iter = torch.utils.data.DataLoader(datasets, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Define the Model**\n",
    "\n",
    "For this example, we will use a 4-layered MLP network with dropout. This is pretty straightforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a four layer neural network with ReLU activation functions\n",
    "\n",
    "batch_size = 64\n",
    "num_epochs = 120\n",
    "learning_rate = 0.001\n",
    "size_hidden1 = 80\n",
    "size_hidden2 = 30\n",
    "size_hidden3 = 10\n",
    "size_output = 1\n",
    "\n",
    "class DNNModel(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.3):\n",
    "        super(DNNModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(51, size_hidden1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.drop1 = nn.Dropout(p=dropout_rate)  \n",
    "\n",
    "        self.fc2 = nn.Linear(size_hidden1, size_hidden2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.drop2 = nn.Dropout(p=dropout_rate)  \n",
    "\n",
    "        self.fc3 = nn.Linear(size_hidden2, size_hidden3)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.drop3 = nn.Dropout(p=dropout_rate)  \n",
    "\n",
    "        self.fc4 = nn.Linear(size_hidden3, size_output)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.drop1(x) \n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.drop2(x)  \n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.drop3(x)  \n",
    "        x = self.fc4(x)\n",
    "        #x = self.sigmoid(x) # no need to apply sigmoid here, as we will use BCEWithLogitsLoss\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Train the model**\n",
    "\n",
    "Let's train the model for 120 epochs. For simplicity, we will not be doing any hyperparameter optimzation or k-fold cross validation. To save time, we have pre-trained the model and saved the weights. The function will train if no weights are present, otherwise, it will simply load the pretrained weights or checkpoint.\n",
    "\n",
    "The dataset is highly imbalanced with 39922 examples with negative outcome and only 5289 calls with positive outcomes (subscribed to term deposits) -- a ratio of 7.55. To compensate for this imbalance we use weighted loss with a pos_weight of 7.55. To improve training, we use xavier initialization and low lr.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNNModel()\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(7.55))\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "import torch.nn.init as init\n",
    "\n",
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Linear):  # Apply to Linear layers only\n",
    "        init.xavier_uniform_(m.weight)  # Xavier (Glorot) initialization\n",
    "        if m.bias is not None:\n",
    "            init.zeros_(m.bias)  # Initialize biases to zero\n",
    "\n",
    "# Apply initialization to the model\n",
    "model.apply(initialize_weights)\n",
    "\n",
    "#run model on device\n",
    "model.to(device)\n",
    "\n",
    "def train(model, num_epochs, criterion, optimizer, train_iter, device):\n",
    "    model.to(device)  # Move model to device\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_iter, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Move to GPU/CPU\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Update weights\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Print average loss every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            avg_loss = running_loss / len(train_iter)\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "\n",
    "def train_load_save_model(model_obj, model_path,num_epochs,criterion, optimizer, train_iter, device):\n",
    "    if path.isfile(model_path):\n",
    "        # load model\n",
    "        print('Loading pre-trained model from: {}'.format(model_path))\n",
    "        model_obj.load_state_dict(torch.load(model_path))\n",
    "    else:    \n",
    "        # train model\n",
    "        # Move model to device\n",
    "        model_obj = model_obj.to(device)\n",
    "        train(model_obj, num_epochs, criterion, optimizer, train_iter, device)\n",
    "        print('Finished training the model. Saving the model to the path: {}'.format(model_path))\n",
    "        torch.save(model_obj.state_dict(), model_path)\n",
    "        \n",
    "        \n",
    "SAVED_MODEL_PATH = 'models/bank_model.pt'\n",
    "# Move input tensors to device\n",
    "X_train = X_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "# Move datasets to device\n",
    "datasets = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "\n",
    "# Ensure data loader is using tensors on the correct device\n",
    "train_iter = torch.utils.data.DataLoader(datasets, batch_size=10, shuffle=True)\n",
    "\n",
    "train_load_save_model(model, SAVED_MODEL_PATH, num_epochs, criterion, optimizer, train_iter,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Training Results**\n",
    "\n",
    "Of course, with hyperparameter optimization we could possibly get better results, but the objective here is to illustrate IG as a post-hoc explainability method, not model optimization. Let's proceed with this model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import roc_auc_score, auc, RocCurveDisplay, confusion_matrix,  ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "model.eval()\n",
    "outputs = model(X_test)\n",
    "predicted = outputs > 0.5\n",
    "total = y_test.cpu().size(0)\n",
    "correct = (predicted.float() == y_test).sum().item()\n",
    "accuracy = correct / total\n",
    "print('Accuracy: ', accuracy)\n",
    "roc_auc = roc_auc_score(y_test.cpu(), outputs.detach().cpu().numpy())\n",
    "print('ROC AUC:', roc_auc)\n",
    "conf_mat = confusion_matrix(y_test.cpu(), predicted.cpu())\n",
    "# Plot confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat)\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  **6. Compute Global explanations using Integrated Gradients**\n",
    "\n",
    "- Here, we can compute feature attribution for all datapoints in the test set and visualize individual feature contributions.\n",
    "- This process is usually time consuming as for each row in the test set, the IG computation has to be repeated n_steps times.\n",
    "- For sake of time, we pre-compute and save the attributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def compute_and_save_ig_attributions(model, X_test, final_column_names, \n",
    "                                     ig_attr_path=\"models/ig_attr_test.npy\", \n",
    "                                     ig_attr_norm_sum_path=\"models/ig_attr_test_norm_sum.npy\", \n",
    "                                     feature_names_path=\"models/feature_names.txt\"):\n",
    "    if not os.path.exists(ig_attr_path) or not os.path.exists(ig_attr_norm_sum_path) or not os.path.exists(feature_names_path):\n",
    "        # Compute IG attributions\n",
    "        ig = IntegratedGradients(model)\n",
    "        ig_attr_test = ig.attribute(X_test, n_steps=50)\n",
    "\n",
    "        # Convert to numpy for saving\n",
    "        ig_attr_test_np = ig_attr_test.detach().numpy()\n",
    "\n",
    "        # Save as a .npy file for fast loading\n",
    "        np.save(ig_attr_path, ig_attr_test_np)\n",
    "\n",
    "        # Also save the summed and normalized version\n",
    "        ig_attr_test_sum = ig_attr_test_np.sum(0)\n",
    "        ig_attr_test_norm_sum = ig_attr_test_sum / np.linalg.norm(ig_attr_test_sum, ord=1)\n",
    "        np.save(ig_attr_norm_sum_path, ig_attr_test_norm_sum)\n",
    "\n",
    "        # Save feature names for reference\n",
    "        with open(feature_names_path, \"w\") as f:\n",
    "            for name in final_column_names:\n",
    "                f.write(f\"{name}\\n\")\n",
    "        print(\"IG attributions computed and saved.\")\n",
    "    else:\n",
    "        print(\"IG attributions already exist. Skipping computation.\")\n",
    "\n",
    "# Call the function and only run IG computations if the precomputed attributions don't exist\n",
    "compute_and_save_ig_attributions(model, X_test, final_column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load precomputed IG attributions\n",
    "ig_attr_test_np = np.load(\"models/ig_attr_test.npy\")\n",
    "\n",
    "# Load summed and normalized IG attributions\n",
    "ig_attr_test_norm_sum = np.load(\"models/ig_attr_test_norm_sum.npy\")\n",
    "\n",
    "# Load feature names\n",
    "with open(\"models/feature_names.txt\", \"r\") as f:\n",
    "    feature_names = [line.strip() for line in f]\n",
    "\n",
    "# Verify data shape\n",
    "print(\"IG Attribution Shape:\", ig_attr_test_np.shape)\n",
    "print(\"Feature Names:\", feature_names)\n",
    "# Create a bar plot for feature attributions\n",
    "x_axis_data = np.arange(len(feature_names))\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.bar(x_axis_data, ig_attr_test_norm_sum, color='salmon', label=\"Int Grads\")\n",
    "plt.xticks(x_axis_data, feature_names, rotation=90, fontsize=10)\n",
    "plt.ylabel(\"Attributions\")\n",
    "plt.title(\"Precomputed Integrated Gradients Feature Importances\")\n",
    "plt.legend()\n",
    "\n",
    "# Draw dotted lines from xticks labels to the y-axis\n",
    "for i in range(len(feature_names)):\n",
    "    plt.axvline(x=i, color='gray', linestyle='dotted', linewidth=0.5)\n",
    "\n",
    "# Draw y-axis\n",
    "plt.axhline(y=0, color='black', linewidth=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global explanations\n",
    "\n",
    "From the bar plot, it can be noted that the features `default_no`, `loan_no` are significant indicators of a positive outcome in the trained model. This means if the client has not defaulted before and if they do not have any loans, the likelihood of these clients to subscribe to a term deposit is high.\n",
    "\n",
    "We also see that the month of May, is attributed to negative outcome. Similarly, if the client is a blue collar worker and is either in the management or technician role leads to negative outcomes. \n",
    "\n",
    "To dig deeper why the month of May leads to negative outcome, let's check the distribution of calls across the months in a year in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'].value_counts().plot(kind='bar') # let's see the distribution of the month column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, here we see that the majority of the calls were made in the month of May! \t\n",
    "-\tSince a large number of calls happen in May, many clients might have already been contacted multiple times, leading to customer fatigue.\n",
    "-\tCustomers may perceive these calls as too aggressive or repetitive, making them less likely to subscribe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local explanations\n",
    "\n",
    "Let's plot the IG attributions for a specific client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot IG attribution for client 100 in the test set. we'll load the data and the model, and then compute the IG attributions for the client\n",
    "client_idx = 100\n",
    "client_data = X_test[client_idx].unsqueeze(0)\n",
    "client_output = model(client_data)\n",
    "client_output_prob = torch.sigmoid(client_output).item()\n",
    "client_output_class = 1 if client_output_prob > 0.5 else 0\n",
    "print(\"Predicted Probability:\", client_output_prob)\n",
    "print(\"Predicted Class:\", client_output_class)\n",
    "print(\"True Class:\", y_test[client_idx].item())\n",
    "\n",
    "#plot IG attributions\n",
    "ig = IntegratedGradients(model)\n",
    "ig_attr_client = ig.attribute(client_data, n_steps=50).squeeze(0).detach().numpy()\n",
    "ig_attr_client_norm = ig_attr_client / np.linalg.norm(ig_attr_client, ord=1)\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.bar(x_axis_data, ig_attr_client_norm, color='salmon', label=\"Int Grads\")\n",
    "plt.xticks(x_axis_data, feature_names, rotation=90, fontsize=10)\n",
    "plt.ylabel(\"Attributions\")\n",
    "plt.title(\"Integrated Gradients Feature Importances for Client 100\")\n",
    "plt.legend()\n",
    "\n",
    "# Draw dotted lines from xticks labels to the y-axis\n",
    "for i in range(len(feature_names)):\n",
    "    plt.axvline(x=i, color='gray', linestyle='dotted', linewidth=0.5)\n",
    "\n",
    "# Draw y-axis\n",
    "plt.axhline(y=0, color='black', linewidth=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**job_blue_collar (Most Negative Attribution)**\n",
    "-\tBeing in a blue-collar job significantly decreased the likelihood of subscribing.\n",
    "-\tPossible reasons:\n",
    "\t-\tBlue-collar workers may have less financial flexibility to invest in term deposits.\n",
    "\t-\tTheir income levels and job stability might not align with long-term savings products.\n",
    "\t-\tHistorically, in banking datasets like UCI’s, blue-collar workers tend to have lower subscription rates.\n",
    "\n",
    "**month_apr (Very Negative Attribution)**\n",
    "- If the marketing call happened in April, the client was significantly less likely to subscribe.\n",
    "- Possible reasons:\n",
    "\t-\tApril could be a time when people prioritize tax payments and avoid new financial commitments.\n",
    "\t-\tSeasonality effects—April might not be an ideal month for term deposits compared to months like September or December.\n",
    "\n",
    "**education_secondary (Negative Attribution)**\n",
    "-\tHaving secondary education instead of higher education might have slightly decreased the likelihood of subscribing.\n",
    "-\tPossible reasons:\n",
    "\t-\tClients with higher education levels (college/university) may be more financially literate and more likely to invest in term deposits.\n",
    "\t-\tSecondary-educated individuals may prefer short-term savings over fixed-term deposits.\n",
    "\n",
    "\n",
    "**Conclusions**\n",
    "\n",
    "- Consider targeting white-collar jobs more aggressively: \n",
    "\t- Blue-collar workers show less interest in term deposits, so marketing strategies might need more tailored financial education.\n",
    "-\tApril campaigns might not be effective: If April shows consistently negative attributions across multiple clients, it might not be an ideal marketing period.\n",
    "-\tEducation matters in financial product marketing: Clients with only secondary education may need simpler messaging or better financial awareness campaigns to improve conversion rates."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
