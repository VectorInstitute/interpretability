{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xyEUzNRnqoPu"
   },
   "source": [
    "# Prototypical Networks:\n",
    "In this notebook, we investigate prototypical networks, which are inherently explainable machine learning (ML) models, applicable to different modalities including imaging. These models work by learning a set of representations for each output class, called prototypes, and calculating the distance of each datapoint from these prototypes to predict its class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ICYY21wfboGj"
   },
   "outputs": [],
   "source": [
    "# https://github.com/n0obcoder/NIH-Chest-X-Rays-Multi-Label-Image-Classification-In-Pytorch/tree/master\n",
    "# https://github.com/cxr-eye-gaze/eye-gaze-dataset\n",
    "import os\n",
    "import re\n",
    "from glob import glob\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from imgaug import augmenters as iaa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from torch.utils.data.sampler import Sampler\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.modules import Module\n",
    "from utils.utils import get_roc_auc_score\n",
    "from utils.utils import prototype_heatmap\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, f1_score, recall_score, precision_score\n",
    "import numpy as np\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "from datetime import datetime\n",
    "\n",
    "from model_intepretability.imaging_copy.dataset.dataset import PrototypicalBatchSampler\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from functools import partial\n",
    "import torch.distributed as dist\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, f1_score, recall_score, precision_score\n",
    "from torch.utils.data import DataLoader,SubsetRandomSampler, TensorDataset\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import torchvision.models as models\n",
    "import torch.distributed as dist\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "plt.rcParams['figure.figsize'] = [25, 10]\n",
    "import gradio as gr\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "import argparse\n",
    "import gc\n",
    "from pathlib import Path\n",
    "from utils.utils import get_roc_auc_score\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BbdIjiOaRCTd"
   },
   "outputs": [],
   "source": [
    "def make_parser():\n",
    "    parser = argparse.ArgumentParser(description='Imaging Explainability')\n",
    "    parser.add_argument('--num_workers', type=int, default=4, help='number of workers')\n",
    "    parser.add_argument('--resize', type=int, default=224, help='Resizing images')\n",
    "\n",
    "\n",
    "\n",
    "    parser.add_argument('--batch_size', type=int, default=32, help='batch size')\n",
    "    parser.add_argument('--epochs', type=int, default=20, help='number of epochs')\n",
    "    parser.add_argument('--lr', type=float, default=1e-3, help='initial learning rate')\n",
    "    parser.add_argument('--scheduler', default=False, action='store_true', help='[USE] scheduler')\n",
    "    parser.add_argument('--step_size', type=int, default=5, help='scheduler step size')\n",
    "\n",
    "\n",
    "    parser.add_argument('--dropout', type=float, default=0.5, help='dropout')\n",
    "\n",
    "\n",
    "\n",
    "    parser.add_argument('--rseed', type=int, default=42, help='Seed for reproducibility')\n",
    "    parser.add_argument('--weight_decay', type=int, default=1e-3, help='Seed for reproducibility')\n",
    "    parser.add_argument('--num_epochs', type=int, default=20, help='Seed for reproducibility')\n",
    "    parser.add_argument('-its', '--iterations',\n",
    "                        type=int,\n",
    "                        help='number of episodes per epoch, default=100',\n",
    "                        default=100)\n",
    "    parser.add_argument('-cTr', '--classes_per_it_tr',\n",
    "                        type=int,\n",
    "                        help='number of random classes per episode for training, default=60',\n",
    "                        default=15)\n",
    "    parser.add_argument('-nsTr', '--num_support_tr',\n",
    "                        type=int,\n",
    "                        help='number of samples per class to use as support for training, default=5',\n",
    "                        default=5)\n",
    "    parser.add_argument('-nqTr', '--num_query_tr',\n",
    "                        type=int,\n",
    "                        help='number of samples per class to use as query for training, default=5',\n",
    "                        default=5)\n",
    "    parser.add_argument('-cVa', '--classes_per_it_val',\n",
    "                        type=int,\n",
    "                        help='number of random classes per episode for validation, default=5',\n",
    "                        default=5)\n",
    "    parser.add_argument('-nsVa', '--num_support_val',\n",
    "                        type=int,\n",
    "                        help='number of samples per class to use as support for validation, default=5',\n",
    "                        default=5)\n",
    "\n",
    "    parser.add_argument('-nqVa', '--num_query_val',\n",
    "                        type=int,\n",
    "                        help='number of samples per class to use as query for validation, default=15',\n",
    "                        default=15)\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4g0ptF6b2CRq"
   },
   "source": [
    "## Data:\n",
    "\n",
    "In this project, we use the \"NIH\" dataset, which is publicly accessible at [here](https://www.kaggle.com/datasets/nih-chest-xrays/data). It contains 112120 chest X-rays corresponding to 14 different conditions, e.g., Pneumonia. The goal is to train a predictive model to classify each image to one or multiple conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1WIOIiVhrr6m"
   },
   "outputs": [],
   "source": [
    "def read_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = image/np.max(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "\n",
    "class XrayDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_path_name):\n",
    "\n",
    "        self.path_name = image_path_name\n",
    "        self.csv_file = csv_file\n",
    "        self.the_chosen, self.all_classes, self.all_classes_dict = self.choose_the_indices()\n",
    "        self.csv_file[\"numeric_targets\"] = self.csv_file['Finding Labels'].apply(lambda x: self.get_tagets(x))\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.csv_file)\n",
    "    def choose_the_indices(self):\n",
    "\n",
    "        max_examples_per_class = 10000 # its the maximum number of examples that would be sampled in the training set for any class\n",
    "        the_chosen = []\n",
    "        all_classes = {}\n",
    "        length = len(self.csv_file)\n",
    "        print('\\nSampling the huuuge training dataset')\n",
    "        for i in tqdm(list(np.random.choice(range(length),length, replace = False))):\n",
    "\n",
    "            temp = str.split(self.csv_file.iloc[i, :]['Finding Labels'], '|')\n",
    "\n",
    "            # special case of ultra minority hernia. we will use all the images with 'Hernia' tagged in them.\n",
    "            if 'Hernia' in temp:\n",
    "                the_chosen.append(i)\n",
    "                for t in temp:\n",
    "                    if t not in all_classes:\n",
    "                        all_classes[t] = 1\n",
    "                    else:\n",
    "                        all_classes[t] += 1\n",
    "                continue\n",
    "\n",
    "            # choose if multiple labels\n",
    "            if len(temp) > 1:\n",
    "                bool_lis = [False]*len(temp)\n",
    "                # check if any label crosses the upper limit\n",
    "                for idx, t in enumerate(temp):\n",
    "                    if t in all_classes:\n",
    "                        if all_classes[t]< max_examples_per_class: # 500\n",
    "                            bool_lis[idx] = True\n",
    "                    else:\n",
    "                        bool_lis[idx] = True\n",
    "                # if all lables under upper limit, append\n",
    "                if sum(bool_lis) == len(temp):\n",
    "                    the_chosen.append(i)\n",
    "                    # maintain count\n",
    "                    for t in temp:\n",
    "                        if t not in all_classes:\n",
    "                            all_classes[t] = 1\n",
    "                        else:\n",
    "                            all_classes[t] += 1\n",
    "            else:        # these are single label images\n",
    "                for t in temp:\n",
    "                    if t not in all_classes:\n",
    "                        all_classes[t] = 1\n",
    "                    else:\n",
    "                        if all_classes[t] < max_examples_per_class: # 500\n",
    "                            all_classes[t] += 1\n",
    "                            the_chosen.append(i)\n",
    "\n",
    "\n",
    "\n",
    "        '''\n",
    "        if len(the_chosen) != len(set(the_chosen)):\n",
    "            print('\\nGadbad !!!')\n",
    "            print('and the difference is: ', len(the_chosen) - len(set(the_chosen)))\n",
    "        else:\n",
    "            print('\\nGood')\n",
    "        '''\n",
    "        with open('all_classes.pkl', 'wb') as file:\n",
    "            pickle.dump(all_classes, file)\n",
    "        return the_chosen, sorted(list(all_classes)), all_classes\n",
    "\n",
    "    def get_tagets(self,row):\n",
    "        labels = str.split(row, '|')\n",
    "\n",
    "        target = torch.zeros(len(self.all_classes))\n",
    "        for lab in labels:\n",
    "            lab_idx = self.all_classes.index(lab)\n",
    "            target[lab_idx] = 1\n",
    "        return target\n",
    "    def get_image(self, idx):\n",
    "        # -- Query the index location of the required file\n",
    "\n",
    "        image_name = self.csv_file.loc[idx,'Image Index']\n",
    "\n",
    "        image_path = glob(os.path.join(self.path_name, '**', image_name), recursive=True)[0]\n",
    "        image = read_image(image_path)\n",
    "        if len(image.shape) == 2: image = np.expand_dims(image, axis=-1)\n",
    "\n",
    "        labels = str.split(self.csv_file.loc[idx,'Finding Labels'], '|')\n",
    "\n",
    "        target = torch.zeros(len(self.all_classes))\n",
    "        for lab in labels:\n",
    "            lab_idx = self.all_classes.index(lab)\n",
    "            target[lab_idx] = 1\n",
    "        mean = [0.485, 0.456, 0.406]\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "        input_size = 224\n",
    "        rseed = 42\n",
    "        seq = iaa.Sequential([iaa.Resize((input_size, input_size))])\n",
    "        image_transform = transforms.Compose([seq.augment_image, transforms.ToTensor(), transforms.Normalize(mean=mean, std=std)])\n",
    "        image = image_transform(image)\n",
    "        return image.float(), target\n",
    "\n",
    "\n",
    "    def num_sort(self, filename):\n",
    "        not_num = re.compile(\"\\D\")\n",
    "        return int(not_num.sub(\"\", filename))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.get_image(idx)\n",
    "        return image,label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5mXIzTpIHtB0"
   },
   "outputs": [],
   "source": [
    "# extracted from: https://github.com/orobix/Prototypical-Networks-for-Few-shot-Learning-PyTorch/blob/master/src/protonet.py\n",
    "def conv_block(in_channels, out_channels):\n",
    "    '''\n",
    "    returns a block conv-bn-relu-pool\n",
    "    '''\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wpPtPAktsM21"
   },
   "outputs": [],
   "source": [
    "# https://github.com/orobix/Prototypical-Networks-for-Few-shot-Learning-PyTorch/tree/master\n",
    "\n",
    "class PrototypicalBatchSampler(object):\n",
    "    '''\n",
    "    PrototypicalBatchSampler: yield a batch of indexes at each iteration.\n",
    "    This version supports multi-label datasets, where each sample may belong to multiple classes.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, labels, classes_per_it, num_samples, iterations):\n",
    "        '''\n",
    "        Initialize the PrototypicalBatchSampler object.\n",
    "        Args:\n",
    "        - labels: binary matrix (n_samples x n_classes), where each row represents the labels of a sample.\n",
    "        - classes_per_it: number of random classes for each iteration.\n",
    "        - num_samples: number of samples for each iteration for each class (support + query).\n",
    "        - iterations: number of iterations (episodes) per epoch.\n",
    "        '''\n",
    "        super(PrototypicalBatchSampler, self).__init__()\n",
    "        self.labels = labels  # Binary matrix of size (n_samples x n_classes)\n",
    "        self.classes_per_it = classes_per_it\n",
    "        self.sample_per_class = num_samples\n",
    "        self.iterations = iterations\n",
    "\n",
    "        # Determine the number of classes and create mappings\n",
    "        self.num_classes = 15\n",
    "        self.classes = [torch.tensor(i) for i in range(self.num_classes)]\n",
    "        # Create a dictionary that maps each class to the indices of samples belonging to it\n",
    "        self.class_to_indices = {c.item(): [] for c in self.classes}\n",
    "        for sample_idx, label_vec in enumerate(self.labels):\n",
    "\n",
    "            for c in torch.nonzero(label_vec).squeeze(1):  # Get active classes for the sample\n",
    "                self.class_to_indices[c.item()].append(sample_idx)\n",
    "\n",
    "        # Convert lists to tensors for efficient indexing\n",
    "\n",
    "        for c in self.class_to_indices:\n",
    "            self.class_to_indices[c] = torch.tensor(self.class_to_indices[c])\n",
    "\n",
    "    def __iter__(self):\n",
    "        '''\n",
    "        Yield a batch of indices.\n",
    "        '''\n",
    "        spc = self.sample_per_class  # Samples per class\n",
    "        cpi = self.classes_per_it    # Classes per iteration\n",
    "\n",
    "        for _ in range(self.iterations):\n",
    "            batch_indices = []\n",
    "            # Randomly sample `cpi` classes\n",
    "            sampled_classes = torch.randperm(self.num_classes)[:cpi]\n",
    "\n",
    "            for c in sampled_classes:\n",
    "                class_indices = self.class_to_indices[c.item()]\n",
    "                if len(class_indices) >= spc:\n",
    "                    # Randomly select `spc` samples from this class\n",
    "                    sampled_indices = class_indices[torch.randperm(len(class_indices))[:spc]]\n",
    "                else:\n",
    "                    # Handle rare classes with fewer samples\n",
    "                    sampled_indices = class_indices\n",
    "                batch_indices.extend(sampled_indices.tolist())\n",
    "\n",
    "            # Shuffle the batch indices to ensure randomness\n",
    "            batch_indices = torch.tensor(batch_indices)\n",
    "            batch_indices = batch_indices[torch.randperm(len(batch_indices))]\n",
    "            for idx in batch_indices:\n",
    "                yield idx.item()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        '''\n",
    "        Return the number of iterations (episodes) per epoch.\n",
    "        '''\n",
    "        return self.iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "suu9cf-rHPAT"
   },
   "outputs": [],
   "source": [
    "#  extracted from: https://github.com/orobix/Prototypical-Networks-for-Few-shot-Learning-PyTorch/blob/master/src/prototypical_loss.py\n",
    "\n",
    "class PrototypicalLoss(Module):\n",
    "    '''\n",
    "    Loss class deriving from Module for the prototypical loss function defined below\n",
    "    '''\n",
    "    def __init__(self, n_support):\n",
    "        super(PrototypicalLoss, self).__init__()\n",
    "        self.n_support = n_support\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        return prototypical_loss(input, target, self.n_support)\n",
    "\n",
    "\n",
    "def euclidean_dist(x, y):\n",
    "    '''\n",
    "    Compute euclidean distance between two tensors\n",
    "    '''\n",
    "    # x: N x D\n",
    "    # y: M x D\n",
    "    n = x.size(0)\n",
    "    m = y.size(0)\n",
    "    d = x.size(1)\n",
    "    if d != y.size(1):\n",
    "        raise Exception\n",
    "\n",
    "    x = x.unsqueeze(1).expand(n, m, d)\n",
    "    y = y.unsqueeze(0).expand(n, m, d)\n",
    "\n",
    "    return torch.pow(x - y, 2).sum(2)\n",
    "\n",
    "\n",
    "\n",
    "def prototypical_loss(original_image,inputs, target, n_support):\n",
    "    \"\"\"\n",
    "    Compute the barycentres by averaging the features of n_support\n",
    "    samples for each class in target, computes then the distances from each\n",
    "    samples' features to each one of the barycentres, computes the\n",
    "    log_probability for each n_query samples for each one of the current\n",
    "    classes, of belonging to a class c. Loss and accuracy are then computed\n",
    "    and returned.\n",
    "\n",
    "    Adjusted for multi-label datasets like NIH.\n",
    "\n",
    "    Args:\n",
    "    - input: the model output for a batch of samples (batch_size x feature_dim).\n",
    "    - target: binary matrix (batch_size x num_classes), where each row is a multi-hot vector.\n",
    "    - n_support: number of samples to use when computing barycentres for each class.\n",
    "    \"\"\"\n",
    "    k = 0\n",
    "    validation_estimated = []\n",
    "    validation_true = []\n",
    "\n",
    "    target_cpu = target\n",
    "    input_cpu = inputs\n",
    "\n",
    "    # Find active classes in the batch\n",
    "    active_classes = torch.nonzero(target_cpu.sum(0)).squeeze(1)\n",
    "    n_classes = len(active_classes)\n",
    "\n",
    "    prototypes = []\n",
    "    query_idxs = []\n",
    "\n",
    "    # Compute prototypes for each active class\n",
    "\n",
    "    for c in active_classes:\n",
    "        # Get indices for samples belonging to class `c`\n",
    "\n",
    "        class_idxs = torch.nonzero(target_cpu[:, c]).squeeze(1)\n",
    "\n",
    "        # Separate support and query samples\n",
    "        support_idxs = class_idxs[:n_support]\n",
    "        query_idxs_c = class_idxs[n_support:]\n",
    "\n",
    "        if len(support_idxs) > 0:\n",
    "            # Compute class prototype\n",
    "            class_prototype = input_cpu[support_idxs].mean(0)\n",
    "            prototypes.append(class_prototype)\n",
    "        else:\n",
    "            print(\"No support samples for class {}\".format(c))\n",
    "        # Add query indices\n",
    "        query_idxs.extend(query_idxs_c.tolist())\n",
    "\n",
    "    if not prototypes or not query_idxs:\n",
    "        # Handle edge case where no valid prototypes or queries are available\n",
    "\n",
    "        return torch.tensor(0.0, device=inputs.device), 0.0  # Loss and AUC as placeholders\n",
    "\n",
    "    prototypes = torch.stack(prototypes)  # Shape: (n_classes, feature_dim)\n",
    "    query_samples = input_cpu[query_idxs]  # Shape: (n_query, feature_dim)\n",
    "\n",
    "    query_samples = F.normalize(query_samples, p=2, dim=1)\n",
    "    prototypes = F.normalize(prototypes, p=2, dim=1)\n",
    "    # Compute distances from queries to prototypes\n",
    "    dists = euclidean_dist(query_samples, prototypes)\n",
    "\n",
    "    # prototype_heatmap(original_image[query_idxs],query_samples,prototypes)\n",
    "    # Compute log probabilities\n",
    "    log_p_y = F.log_softmax(-dists, dim=1)\n",
    "\n",
    "    # Multi-label target construction for queries\n",
    "    query_targets = target_cpu[query_idxs][:, active_classes]\n",
    "\n",
    "\n",
    "\n",
    "    loss_val = F.binary_cross_entropy_with_logits(-dists, query_targets.float())\n",
    "    # Multi-label accuracy\n",
    "    preds = (log_p_y > 0).float()  # Threshold at 0\n",
    "\n",
    "\n",
    "    # Compute AUC\n",
    "    validation_estimated = torch.exp(log_p_y).detach().cpu().numpy()\n",
    "    validation_true = query_targets.detach().cpu().numpy()\n",
    "\n",
    "    auc_val = get_roc_auc_score(validation_true, validation_estimated)\n",
    "\n",
    "    return loss_val, auc_val,query_targets,torch.exp(log_p_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H9aKuxozHclu"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, f1_score, recall_score, precision_score\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "\n",
    "def get_roc_auc_score(y_true, y_probs):\n",
    "    '''\n",
    "    Uses roc_auc_score function from sklearn.metrics to calculate the micro ROC AUC score for a given y_true and y_probs.\n",
    "    '''\n",
    "\n",
    "    with open('all_classes.pkl', 'rb') as all_classes:\n",
    "        all_classes = pickle.load(all_classes)\n",
    "\n",
    "    NoFindingIndex = all_classes.get('No Finding', -1)\n",
    "    class_roc_auc_list = []\n",
    "    useful_classes_roc_auc_list = []\n",
    "\n",
    "    for i in range(y_true.shape[1]):\n",
    "        if len(np.unique(y_true[:, i])) > 1:\n",
    "            class_roc_auc = roc_auc_score(y_true[:, i], y_probs[:, i])\n",
    "            class_roc_auc_list.append(class_roc_auc)\n",
    "            if i != NoFindingIndex:\n",
    "                useful_classes_roc_auc_list.append(class_roc_auc)\n",
    "    return np.mean(np.array(useful_classes_roc_auc_list))\n",
    "\n",
    "def prototype_heatmap(xray_image,image_reps,prototype_rep):\n",
    "\n",
    "\n",
    "    similarities = torch.mm(image_reps, prototype_rep.T)\n",
    "    assigned_prototypes = prototype_rep[torch.argmax(similarities, dim=1),:]\n",
    "\n",
    "    for i, (image,image_rep) in enumerate(zip(xray_image,image_reps)):\n",
    "        assigned_proto = prototype_rep[torch.argmax(similarities[i,:]),:].unsqueeze(0)\n",
    "        image_rep = F.normalize(image_rep.unsqueeze(0).float(), p=2, dim=1)  # Normalize along the channels\n",
    "        assigned_proto = F.normalize(assigned_proto.float(), p=2, dim=1)  # Normalize along the channels\n",
    "\n",
    "        # Calculate cosine similarity at each pixel\n",
    "        similarity_map = F.cosine_similarity(image_rep, assigned_proto, dim=0)  # Similarity along the channel dimension\n",
    "\n",
    "        similarity_map = (similarity_map - similarity_map.min()) / (similarity_map.max() - similarity_map.min())\n",
    "        resized_similarity_map = torch.nn.functional.interpolate(\n",
    "            similarity_map.reshape(112,112).unsqueeze(0).unsqueeze(0),\n",
    "            size=image.size()[-2:],  # Height and Width of the image\n",
    "            mode='bilinear',\n",
    "            align_corners=False\n",
    "            ).squeeze()\n",
    "        plt.imshow(image[0].cpu().numpy(), cmap='gray')\n",
    "        plt.imshow(resized_similarity_map.cpu().detach().numpy(), cmap='jet', alpha=0.5)\n",
    "        plt.colorbar(label='Similarity')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        plt.savefig(\"prototype_heatmap.png\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "397_WsRyHeVL"
   },
   "outputs": [],
   "source": [
    "class ProtoNet(nn.Module):\n",
    "    '''\n",
    "    Model as described in the reference paper,\n",
    "    source: https://github.com/jakesnell/prototypical-networks/blob/f0c48808e496989d01db59f86d4449d7aee9ab0c/protonets/models/few_shot.py#L62-L84\n",
    "    '''\n",
    "    def __init__(self, x_dim=3, hid_dim=64, z_dim=64):\n",
    "        super(ProtoNet, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            conv_block(x_dim, hid_dim),\n",
    "            conv_block(hid_dim, hid_dim),\n",
    "            conv_block(hid_dim, hid_dim),\n",
    "            conv_block(hid_dim, z_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x.view(x.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U2I2aBxeD87z"
   },
   "outputs": [],
   "source": [
    "def prototype_heatmap(xray_image,image_reps,prototype_rep):\n",
    "\n",
    "\n",
    "    similarities = torch.mm(image_reps, prototype_rep.T)\n",
    "    assigned_prototypes = prototype_rep[torch.argmax(similarities, dim=1),:]\n",
    "\n",
    "    for i, (image,image_rep) in enumerate(zip(xray_image,image_reps)):\n",
    "        assigned_proto = prototype_rep[torch.argmax(similarities[i,:]),:].unsqueeze(0)\n",
    "        image_rep = F.normalize(image_rep.unsqueeze(0).float(), p=2, dim=1)  # Normalize along the channels\n",
    "        assigned_proto = F.normalize(assigned_proto.float(), p=2, dim=1)  # Normalize along the channels\n",
    "\n",
    "        # Calculate cosine similarity at each pixel\n",
    "        similarity_map = F.cosine_similarity(image_rep, assigned_proto, dim=0)  # Similarity along the channel dimension\n",
    "\n",
    "        similarity_map = (similarity_map - similarity_map.min()) / (similarity_map.max() - similarity_map.min())\n",
    "        resized_similarity_map = torch.nn.functional.interpolate(\n",
    "            similarity_map.reshape(112,112).unsqueeze(0).unsqueeze(0),\n",
    "            size=image.size()[-2:],  # Height and Width of the image\n",
    "            mode='bilinear',\n",
    "            align_corners=False\n",
    "            ).squeeze()\n",
    "        plt.imshow(image[0].cpu().numpy(), cmap='gray')\n",
    "        plt.imshow(resized_similarity_map.cpu().detach().numpy(), cmap='jet', alpha=0.5)\n",
    "        plt.colorbar(label='Similarity')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        plt.savefig(\"prototype_heatmap.png\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ct-O_9EnEPGt"
   },
   "outputs": [],
   "source": [
    "def train_prototype(args, train_ds,test_ds):\n",
    "\n",
    "\n",
    "\n",
    "    global f1_list,auc_list, precision_list, recall_list\n",
    "    setup()\n",
    "    init_fn = partial(\n",
    "        worker_init_fn,\n",
    "        num_workers=args.num_workers,\n",
    "        rank=dist.get_rank(),\n",
    "        seed=args.rseed,\n",
    "    )\n",
    "\n",
    "    test_sampler = DistributedSampler(test_ds, shuffle=True)\n",
    "\n",
    "    test_dl = DataLoader(test_ds,sampler=test_sampler, batch_size=args.batch_size,worker_init_fn=init_fn)\n",
    "\n",
    "    # setup()\n",
    "    torch.cuda.set_device(int(os.environ[\"LOCAL_RANK\"]))\n",
    "    torch.cuda.empty_cache()\n",
    "    device_id = torch.cuda.current_device()\n",
    "\n",
    "\n",
    "\n",
    "    for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(train_ds)))):\n",
    "\n",
    "        print(\"fold:\", fold)\n",
    "\n",
    "        print('Fold {}'.format(fold + 1))\n",
    "\n",
    "        train_subset = Subset(train_ds, train_idx)\n",
    "        val_subset = Subset(train_ds, val_idx)\n",
    "        train_sampler = DistributedSampler(train_subset, shuffle=True)\n",
    "        valid_sampler = DistributedSampler(val_subset, shuffle=True)\n",
    "        classes_per_it_tr = args.classes_per_it_tr\n",
    "        num_samples_tr = args.num_support_tr + args.num_query_tr\n",
    "\n",
    "        classes_per_it_val = args.classes_per_it_val\n",
    "        num_samples_val = args.num_support_val + args.num_query_val\n",
    "\n",
    "        classes = train_ds.csv_file[\"numeric_targets\"]\n",
    "\n",
    "        train_sampler = PrototypicalBatchSampler(labels=classes,\n",
    "                                    classes_per_it=classes_per_it_tr,\n",
    "                                    num_samples=num_samples_tr,\n",
    "                                    iterations=args.iterations)\n",
    "        valid_sampler = PrototypicalBatchSampler(labels=classes,\n",
    "                                    classes_per_it=classes_per_it_val,\n",
    "                                    num_samples=num_samples_val,\n",
    "                                    iterations=args.iterations)\n",
    "\n",
    "        init_fn = partial(worker_init_fn,num_workers=args.num_workers,rank=dist.get_rank(),seed=args.rseed)\n",
    "        train_dl = DataLoader(train_ds, sampler=train_sampler,batch_size=args.batch_size,worker_init_fn=init_fn,pin_memory=False,drop_last=True,num_workers=args.num_workers)\n",
    "        valid_dl = DataLoader(train_ds, sampler=valid_sampler, batch_size=args.batch_size,worker_init_fn=init_fn,pin_memory=False,drop_last=True,num_workers=args.num_workers)\n",
    "        model2 = ProtoNet()\n",
    "        model2 = model2.cuda(device_id)\n",
    "        # model2 = DDP(model2, device_ids=[device_id])#,find_unused_parameters=True)\n",
    "\n",
    "\n",
    "        optimizer = optim.AdamW(model2.parameters(), lr=args.lr,weight_decay=args.weight_decay)\n",
    "        try:\n",
    "            model2, optimizer, start_epoch, _ = load_checkpoint(model2, optimizer,\"output_weight/proto.pth\")\n",
    "            print(f\"Resuming from epoch {start_epoch + 1}\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"No checkpoint found, starting frsom scratch\")\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=0.995, step_size=1)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        train_auc = []\n",
    "        val_auc = []\n",
    "        for epoch in range(args.num_epochs):\n",
    "\n",
    "            model2.train()\n",
    "            num_batches=0\n",
    "\n",
    "            k=0\n",
    "            tr_iter = iter(train_dl)\n",
    "\n",
    "            for batch in tqdm(tr_iter):\n",
    "                images,labels = batch\n",
    "                optimizer.zero_grad()\n",
    "                images = images.cuda(device_id, non_blocking=True)\n",
    "                labels = labels.cuda(device_id, non_blocking=True)\n",
    "                image_rep= model2(images.float())\n",
    "                active_classes = torch.nonzero(labels.sum(0)).squeeze(1)\n",
    "                loss, auc,target,prob = prototypical_loss(images,image_rep, target=labels,\n",
    "                                n_support=args.num_support_tr)\n",
    "\n",
    "                train_auc.append(auc)\n",
    "\n",
    "                loss = Variable(loss, requires_grad = True)\n",
    "                loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "                if (num_batches+1)%100==0:\n",
    "                    save_checkpoint(model2, optimizer, epoch, loss.item(), file_path=f\"output_weight/proto_backup.pth\")\n",
    "\n",
    "                if (num_batches+1)%200==0:\n",
    "                    save_checkpoint(model2, optimizer, epoch, loss.item(), file_path=f\"output_weight/proto.pth\")\n",
    "\n",
    "                break\n",
    "            avg_auc = np.mean(train_auc[-args.iterations:])   #??????\n",
    "\n",
    "            print('Avg Train AUC: {}'.format(avg_auc))\n",
    "            model2.eval()\n",
    "\n",
    "            with torch.set_grad_enabled(False):\n",
    "\n",
    "                k = 0\n",
    "                for val_batches,(images,labels) in enumerate(valid_dl):\n",
    "\n",
    "                    labels =  labels.cuda(device_id, non_blocking=True)\n",
    "\n",
    "\n",
    "                    images = images.cuda(device_id, non_blocking=True)\n",
    "                    image_rep = model2(images)\n",
    "\n",
    "                    _, auc,target,prob = prototypical_loss(images,image_rep, target=labels,\n",
    "                                n_support=args.num_support_val)\n",
    "\n",
    "                    val_auc.append(auc)#.item())\n",
    "\n",
    "                    k += prob.shape[0]\n",
    "\n",
    "                avg_val_auc = np.mean(val_auc[-args.iterations:])\n",
    "\n",
    "\n",
    "            print(\"epoch\",epoch,\":\",\"train_AUC:\",avg_auc,\"val_AUC\",avg_val_auc)\n",
    "            model2.eval()\n",
    "        with torch.set_grad_enabled(False):\n",
    "\n",
    "\n",
    "            k = 0\n",
    "\n",
    "            avg_acc = []\n",
    "            for epoch in range(10):\n",
    "                for images,labels in test_dl:\n",
    "\n",
    "\n",
    "                    images, labels = images.cuda(device_id, non_blocking=True), labels.cuda(device_id, non_blocking=True)\n",
    "\n",
    "                    image_rep = model2(images)\n",
    "                    _, auc,target,prob = prototypical_loss(images,image_rep, target=labels,\n",
    "                                n_support=args.num_support_val)\n",
    "                    avg_acc.append(auc.item())\n",
    "\n",
    "\n",
    "            avg_acc = np.mean(avg_acc)\n",
    "            print('Test Acc: {}'.format(avg_acc))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    logging.info('Finished training.')\n",
    "\n",
    "    dist.destroy_process_group()\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hGXZl_MBDb86"
   },
   "outputs": [],
   "source": [
    "args = make_parser().parse_args()\n",
    "auc_list , precision_list, recall_list, f1_list = [], [], [], []\n",
    "random.seed(args.rseed)\n",
    "np.random.seed(args.rseed)\n",
    "torch.manual_seed(args.rseed)\n",
    "torch.cuda.manual_seed(args.rseed)\n",
    "torch.cuda.manual_seed_all(args.rseed)\n",
    "\n",
    "image_path = \"/datasets/nih-chest-xrays\"\n",
    "\n",
    "csv_file = pd.read_csv(os.path.join(image_path,\"Data_Entry_2017.csv\"))\n",
    "test_split = os.path.join(image_path,\"test_list.txt\")\n",
    "train_val_split = os.path.join(image_path,\"train_val_list.txt\")\n",
    "with open(train_val_split, 'r') as f:\n",
    "    train_val_images = f.read().splitlines()\n",
    "with open(test_split, 'r') as f:\n",
    "    test_images = f.read().splitlines()\n",
    "\n",
    "train_df = csv_file[csv_file['Image Index'].isin(train_val_images)]\n",
    "\n",
    "test_df = csv_file[csv_file['Image Index'].isin(test_images)]\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "train_ds = XrayDataset(train_df, image_path)\n",
    "test_ds = XrayDataset(test_df, image_path)\n",
    "train_prototype(args, train_ds,test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_VmaBegTTNZ"
   },
   "source": [
    "## References\n",
    "[[1] Prototypical networks for few-shot learning](https://proceedings.neurips.cc/paper_files/paper/2017/hash/cb8da6767461f2812ae4290eac7cbc42-Abstract.html)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
