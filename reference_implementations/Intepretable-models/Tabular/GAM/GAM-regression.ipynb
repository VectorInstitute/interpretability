{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized Additive Model (GAM) for regression tasks\n",
    "\n",
    "This example illustrates the use of GAMs for regression tasks. We'll use:\n",
    "\n",
    "### Regression Dataset \n",
    "\n",
    "https://www.kaggle.com/datasets/mirichoi0218/insurance\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.5878</td>\n",
       "      <td>1018.7</td>\n",
       "      <td>83.675</td>\n",
       "      <td>3.5758</td>\n",
       "      <td>23.979</td>\n",
       "      <td>1086.2</td>\n",
       "      <td>549.83</td>\n",
       "      <td>134.67</td>\n",
       "      <td>11.898</td>\n",
       "      <td>0.32663</td>\n",
       "      <td>81.952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.2932</td>\n",
       "      <td>1018.3</td>\n",
       "      <td>84.235</td>\n",
       "      <td>3.5709</td>\n",
       "      <td>23.951</td>\n",
       "      <td>1086.1</td>\n",
       "      <td>550.05</td>\n",
       "      <td>134.67</td>\n",
       "      <td>11.892</td>\n",
       "      <td>0.44784</td>\n",
       "      <td>82.377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.9045</td>\n",
       "      <td>1018.4</td>\n",
       "      <td>84.858</td>\n",
       "      <td>3.5828</td>\n",
       "      <td>23.990</td>\n",
       "      <td>1086.5</td>\n",
       "      <td>550.19</td>\n",
       "      <td>135.10</td>\n",
       "      <td>12.042</td>\n",
       "      <td>0.45144</td>\n",
       "      <td>83.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.7436</td>\n",
       "      <td>1018.3</td>\n",
       "      <td>85.434</td>\n",
       "      <td>3.5808</td>\n",
       "      <td>23.911</td>\n",
       "      <td>1086.5</td>\n",
       "      <td>550.17</td>\n",
       "      <td>135.03</td>\n",
       "      <td>11.990</td>\n",
       "      <td>0.23107</td>\n",
       "      <td>82.505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.7516</td>\n",
       "      <td>1017.8</td>\n",
       "      <td>85.182</td>\n",
       "      <td>3.5781</td>\n",
       "      <td>23.917</td>\n",
       "      <td>1085.9</td>\n",
       "      <td>550.00</td>\n",
       "      <td>134.67</td>\n",
       "      <td>11.910</td>\n",
       "      <td>0.26747</td>\n",
       "      <td>82.028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0  4.5878  1018.7  83.675  3.5758  23.979  1086.2  549.83  134.67  11.898   \n",
       "1  4.2932  1018.3  84.235  3.5709  23.951  1086.1  550.05  134.67  11.892   \n",
       "2  3.9045  1018.4  84.858  3.5828  23.990  1086.5  550.19  135.10  12.042   \n",
       "3  3.7436  1018.3  85.434  3.5808  23.911  1086.5  550.17  135.03  11.990   \n",
       "4  3.7516  1017.8  85.182  3.5781  23.917  1085.9  550.00  134.67  11.910   \n",
       "\n",
       "        CO     NOX  \n",
       "0  0.32663  81.952  \n",
       "1  0.44784  82.377  \n",
       "2  0.45144  83.776  \n",
       "3  0.23107  82.505  \n",
       "4  0.26747  82.028  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23479,) (5870,) (7384,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import f1_score,PrecisionRecallDisplay, RocCurveDisplay, classification_report\n",
    "import os\n",
    "from pygam import LinearGAM, s, f\n",
    "import joblib\n",
    "\n",
    "np.random.seed(42)\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the folder path\n",
    "folder_path = '../../../Post-hoc/datasets/gas+turbine+co+and+nox+emission+data+set'\n",
    "\n",
    "# Load the CSV files\n",
    "files_to_load = ['gt_2011.csv', 'gt_2012.csv', 'gt_2013.csv', 'gt_2014.csv']\n",
    "dataframes = [pd.read_csv(os.path.join(folder_path, file)) for file in files_to_load]\n",
    "\n",
    "\n",
    "# Concatenate the dataframes\n",
    "train_val_data = pd.concat(dataframes, ignore_index=True)\n",
    "display(train_val_data.head())\n",
    "\n",
    "# Load the test data\n",
    "test_data = pd.read_csv(os.path.join(folder_path, 'gt_2015.csv'))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_val_data = pd.DataFrame(scaler.fit_transform(train_val_data), columns=train_val_data.columns)\n",
    "test_data = pd.DataFrame(scaler.transform(test_data), columns=test_data.columns)\n",
    "\n",
    "\n",
    "# Split the training and validation data\n",
    "train_data, val_data = train_test_split(train_val_data, test_size=0.2, random_state=42)\n",
    "\n",
    "#use column TEY as target\n",
    "target = 'TEY'\n",
    "X_train = train_data.drop(target, axis=1)\n",
    "y_train = train_data[target]\n",
    "X_val = val_data.drop(target, axis=1)\n",
    "y_val = val_data[target]\n",
    "X_test = test_data.drop(target, axis=1)\n",
    "y_test = test_data[target]\n",
    "\n",
    "print(y_train.shape, y_val.shape, y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.Define a GAM model for regression**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# define gam for regression task\n",
    "\n",
    "# initialize the first term\n",
    "\n",
    "term = s(0)\n",
    "\n",
    "# dynamically add more terms - use smooth function for numerical columns and factor function for categorical columns\n",
    "\n",
    "for i, col in enumerate(X_train.columns):\n",
    "    if X_train[col].dtype == 'int64':\n",
    "        term += s(i)\n",
    "    else:\n",
    "        term += f(i)\n",
    "    \n",
    "gam = LinearGAM(terms=term,n_splines=5, lam=0.1).fit(X_train.values, y_train.values)  \n",
    "\n",
    "print(gam.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warning\n",
    "\n",
    "Large dataset size or large n_splines size can increase training time an dmemory exponentially. If you undergo OOM error or if Juputer crashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the target variable on the test set\n",
    "y_pred = gam.predict(X_test)\n",
    "\n",
    "\n",
    "# Calculate the performance metrics for regression\n",
    "mse = np.mean((y_test - y_pred)**2)\n",
    "mae = np.mean(np.abs(y_test - y_pred))\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the 4 most significant features, plot the shape functions of the GAM model in a 2x2 subplot. \n",
    "# rescale the features to their original scale using the saved scaling parameters\n",
    "\n",
    "# Get the feature names\n",
    "feature_names = X.columns\n",
    "\n",
    "# Get the p-values of the features in the GAM model\n",
    "p_values = gam.statistics_[\"p_values\"]\n",
    "\n",
    "# Get the indices of the 4 most significant features\n",
    "#top_features_indices = np.argsort(np.abs(p_values))[:4]\n",
    "#pick 4 random features\n",
    "top_features_indices = [0, 1, 2, 3]\n",
    "#top_features_indices = np.argsort(np.abs(p_values))[:4]\n",
    "\n",
    "# Filter out any indices that are out of bounds\n",
    "top_features_indices = [i for i in top_features_indices if i < len(X.columns)]\n",
    "print(top_features_indices)\n",
    "\n",
    "# Get the feature names of the 4 most significant features\n",
    "top_features = [feature_names[int(i)] for i in top_features_indices]\n",
    "\n",
    "\n",
    "#load the saved scaler and rescale the features to their original scale\n",
    "scaler = joblib.load(\"scaler_insurance.pkl\")\n",
    "scaler_mean = scaler.mean_\n",
    "scaler_var = scaler.var_\n",
    "\n",
    "# Rescale the features to their original scale\n",
    "X_test_rescaled = X_test.copy()\n",
    "numerical_cols_in_test = [col for col in numerical_columns if col in X_test_rescaled.columns]\n",
    "X_test_rescaled[numerical_cols_in_test] = (X_test[numerical_cols_in_test] * np.sqrt(scaler_var[:len(numerical_cols_in_test)])) + scaler_mean[:len(numerical_cols_in_test)]\n",
    "\n",
    "# get the mapping for the categorical variables\n",
    "#label_encoders = joblib.load(\"label_encoders_insurance.pkl\")\n",
    "\n",
    "#print the mapping for the categorical variables\n",
    "# for col in categorical_features:\n",
    "#     print(f\"Mapping for {col}: {dict(enumerate(label_encoders[col].classes_))}\")\n",
    "\n",
    "# Plot the shape functions of the GAM model for the 4 most significant features\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    if i < len(top_features_indices):\n",
    "        term_index = int(top_features_indices[i])\n",
    "        XX = gam.generate_X_grid(term=term_index)\n",
    "        XX_rescaled = XX.copy()\n",
    "        if feature_names[term_index] in numerical_columns:\n",
    "            col_index = numerical_columns.index(feature_names[term_index])\n",
    "            XX_rescaled[:, term_index] = XX[:, term_index] * np.sqrt(scaler_var[col_index]) + scaler_mean[col_index]\n",
    "        pdep, confi = gam.partial_dependence(term=term_index, width=.95)\n",
    "        ax.plot(XX_rescaled[:, term_index], pdep)\n",
    "        ax.plot(XX_rescaled[:, term_index], confi, c='r', ls='--')\n",
    "        ax.set_title(f\"Feature: {top_features[i]}\")\n",
    "        if feature_names[term_index] in category_columns:\n",
    "            ax.set_xticks(range(len(label_encoders[feature_names[term_index]].classes_)))\n",
    "            ax.set_xticklabels(label_encoders[feature_names[term_index]].classes_, rotation=90)\n",
    "        ax.set_xlabel(top_features[i])\n",
    "        ax.set_ylabel(\"Partial Dependence\")\n",
    "    else:\n",
    "        ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Done\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
