{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shapley's Additive Explanations\n",
    "\n",
    "This Jupyter notebook explains how SHAP library can be used to provide explanations for a black box model. We will use the TreeSHAP and KernelSHAP modules to provide explanations for a Gradient Boosted Decision Tree  (GBDT) for tabular data and neural network. We will compare explanations provided by LIME and SHAP. \n",
    "\n",
    "\n",
    "## **1. Import required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as numpy\n",
    "import shap\n",
    "shap.initjs()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default') \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  **2. Load Dataset**\n",
    "\n",
    "We will use the Heart Failure Prediction Dataset from Kaggle available from [this download link](https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset). The Behavioral Risk Factor Surveillance System (BRFSS) is a health-related telephone survey that is collected annually by the CDC. Each year, the survey collects responses from over 400,000 Americans on health-related risk behaviors, chronic health conditions, and the use of preventative services. It has been conducted every year since 1984. \n",
    "\n",
    "This dataset contains 3 files:\n",
    "\n",
    "1. **diabetes _ 012 _ health _ indicators _ BRFSS2015.csv** is a clean dataset of 253,680 survey responses to the CDC's BRFSS2015. The target variable Diabetes_012 has 3 classes. 0 is for no diabetes or only during pregnancy, 1 is for prediabetes, and 2 is for diabetes. There is class imbalance in this dataset. This dataset has 21 feature variables\n",
    "\n",
    "2. **diabetes _ binary _ 5050split _ health _ indicators _ BRFSS2015.csv** is a clean dataset of 70,692 survey responses to the CDC's BRFSS2015. It has an equal 50-50 split of respondents with no diabetes and with either prediabetes or diabetes. The target variable Diabetes_binary has 2 classes. 0 is for no diabetes, and 1 is for prediabetes or diabetes. This dataset has 21 feature variables and is balanced.\n",
    "\n",
    "3. **diabetes _ binary _ health _ indicators _ BRFSS2015.csv** is a clean dataset of 253,680 survey responses to the CDC's BRFSS2015. The target variable Diabetes_binary has 2 classes. 0 is for no diabetes, and 1 is for prediabetes or diabetes. This dataset has 21 feature variables and is not balanced.\n",
    "\n",
    "\n",
    "For a start, let's use subset 2 which is the balanced-binary dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/diabetes-health-indicators/diabetes_binary_5050split_health_indicators_BRFSS2015.csv')\n",
    "df.head()\n",
    "\n",
    "X = df.drop(columns=['Diabetes_binary'])\n",
    "y = df['Diabetes_binary']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "gbdt_model = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=42)\n",
    "\n",
    "gbdt_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Predict probabilities\n",
    "y_pred_proba = gbdt_model.predict_proba(X_test)[:, 1]\n",
    "X_test = pd.DataFrame(X_test, columns=X_train.columns)\n",
    "y_pred = gbdt_model.predict(X_test)\n",
    "\n",
    "# Calculate AUC\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"AUC: {auc:.4f}, F1: {f1:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Global Model explanations predictions using TreeSHAP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = shap.TreeExplainer(gbdt_model).shap_values(X_train)\n",
    "shap.summary_plot(shap_values, X_train, plot_type='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tTop Features Driving Predictions\n",
    "\t-\tGenHlth (General Health) is the most influential predictor of diabetes in your model. This suggests that a person’s self-reported general health has a strong correlation with diabetes risk.\n",
    "\t-\tBMI (Body Mass Index) and Age - this  aligns with medical knowledge that higher BMI and older age increase diabetes risk.\n",
    "\t-\tHighBP (High Blood Pressure) and HighChol (High Cholesterol)- this  reinforces known comorbidities of diabetes.\n",
    "2.\tModerately Important Features\n",
    "\t-\tIncome and Sex p\n",
    "\t-\tHeartDiseaseorAttack - makes sense since cardiovascular conditions often co-occur with diabetes.\n",
    "\t-\tCholCheck (Cholesterol Check Frequency) likely indicates whether people who get regular checkups are at a higher or lower risk.\n",
    "3.\tLess Influential Features\n",
    "\t-\tFeatures like DiffWalk (Difficulty Walking), MentHlth (Mental Health), Veggies (Vegetable Consumption), and Stroke have smaller SHAP values, indicating they have a weaker effect on diabetes prediction.\n",
    "\t-\tPhysActivity (Physical Activity) has a surprisingly low impact, which could mean that in this dataset, physical activity is not as strong a differentiator for diabetes risk as expected.\n",
    "\t-\tNoDocbcCost (No Doctor Visit Due to Cost) and AnyHealthcare appear at the bottom, meaning they contribute very little to predictions.\n",
    "\n",
    "We typycall use mean absolute values of SHAP to illustrate feature importance, regardless of their positive or negative effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary plot\n",
    "shap.summary_plot(shap_values, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **X-Axis (SHAP Values: Impact on Model Output)**\n",
    "\t-\tA negative SHAP value (left side) means that the feature lowers the diabetes risk.\n",
    "\t-\tA positive SHAP value (right side) means that the feature increases the diabetes risk.\n",
    "\t-\tPoints close to 0 indicate low impact.\n",
    "\t\n",
    "2.\t**Color Gradient (Feature Value: Blue → Red)**\n",
    "\t-\tBlue = Lower feature values\n",
    "\t-\tRed = Higher feature values\n",
    "\t-\tThis helps in understanding whether high or low feature values push the model towards predicting diabetes.\n",
    "\n",
    "\n",
    "Let's dive deeper:\n",
    "\n",
    "1. **General Health (GenHlth) is the Most Important Feature**\n",
    "\t-\tHigher values of GenHlth (poor general health) increase diabetes risk (red points on the right).\n",
    "\t-\tLower values of GenHlth (good health) decrease diabetes risk (blue points on the left).\n",
    "\n",
    "2. **BMI and Age are Strong Predictors**\n",
    "\t-\tHigher BMI (red points) is associated with a higher risk (positive SHAP values).\n",
    "\t-\tLower BMI (blue points) is linked to lower risk.\n",
    "\t-\tAge follows the same pattern, with older individuals having a higher risk.\n",
    "\n",
    "3. **High Blood Pressure (HighBP) and High Cholesterol (HighChol) Are Significant**\n",
    "\t-\tHighBP: High values (red) increase diabetes risk, while low values (blue) lower it.\n",
    "\t-\tHighChol: Similarly, people with high cholesterol levels are more likely to have diabetes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Local explanations for specific instance using SHAP**\n",
    "\n",
    "In addition to providing global explanations, SHAP also allows instance-specific explanations. Here we are applying SHAP to explain the 10th patient data from the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Select the 10th example from the test set\u001b[39;00m\n\u001b[1;32m      2\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m9\u001b[39m\n\u001b[0;32m----> 3\u001b[0m example \u001b[38;5;241m=\u001b[39m \u001b[43mX_test\u001b[49m\u001b[38;5;241m.\u001b[39miloc[index]\n\u001b[1;32m      4\u001b[0m display(example)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrue label: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_test\u001b[38;5;241m.\u001b[39miloc[index]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "# Select the 10th example from the test set\n",
    "index = 9\n",
    "example = X_test.iloc[index]\n",
    "display(example)\n",
    "print(f\"True label: {y_test.iloc[index]}\")\n",
    "print(f\"Predicted probability: {gbdt_model.predict_proba([example])[0, 1]}\")\n",
    "print(f\"Predicted class: {gbdt_model.predict([example])[0]}\")\n",
    "\n",
    "# Get SHAP values for the 10th example\n",
    "shap_values_single = shap.TreeExplainer(gbdt_model).shap_values(example)\n",
    "\n",
    "# Plot the SHAP values for the 10th example\n",
    "shap.force_plot(shap.TreeExplainer(gbdt_model).expected_value, shap_values_single, example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.1 How do we inteprete these results?**\n",
    "\n",
    "1.\tBase Value (Expected Value):\n",
    "    - \tThis is the average model prediction across the dataset.\n",
    "    -  \tIn this case, it is approximately -0.08087.\n",
    "2.\tFinal Prediction (f(x)):\n",
    "    -\tThe final model prediction for this sample is -3.01, which is lower than the base value.\n",
    "    -\tSince SHAP values explain how features push the prediction higher (towards diabetes) or lower (away from diabetes), a negative prediction likely means a low probability of diabetes for this individual.\n",
    "3.\tFeatures that Decreased the Prediction (Blue Arrows - Left Side)\n",
    "    -\tGenHlth = 1 (Good General Health)\n",
    "    -\tBMI = 18 (Low BMI)\n",
    "    -\tHighBP = 0 (No High Blood Pressure)\n",
    "    -\tHighChol = 0 (No High Cholesterol)\n",
    "    -\tIncome = 8 (High Income)\n",
    "\n",
    "The <span style=\"color:blue\">blue features</span> pushes the predictions lower, while the <span style=\"color:red\">red features</span> push the predictions slightly higher, but was not strong enough to overcome other health-protective features. In other words:\n",
    "\n",
    "-\tThis individual is predicted to have a low diabetes risk, as indicated by the negative final prediction (-3.01).\n",
    "-\tThe most influential features driving the low prediction are:\n",
    "-\tGood General Health\n",
    "-\tLow BMI\n",
    "-\tNo High Blood Pressure\n",
    "-\tNo High Cholesterol\n",
    "-\tHigh Income\n",
    "-\tThe only feature slightly increasing the risk is Age = 10, but its effect is weak compared to the protective features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.2 Compare this with LIME**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "import lime.lime_tabular\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, mode='regression', feature_names=X_train.columns.tolist(), discretize_continuous=True)\n",
    "\n",
    "# Pick the 10th instance from the test data\n",
    "exp = explainer.explain_instance(example, gbdt_model.predict, num_features=21) \n",
    "display(example) \n",
    "exp.show_in_notebook()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.3 Intepretation of plots**\n",
    "- Both methods recognize GenHlth (General Health), BMI, HighBP, HighChol, and Age as key predictors for diabetes risk.\n",
    "    -  Both show that good general health, lower BMI, and absence of high blood pressure push the prediction towards a lower diabetes risk.\n",
    "\n",
    "- Both differentiate between positive and negative influences\n",
    "\t\n",
    "- Both highlight the impact of Age and Health Conditions\n",
    "\t-\tIn both visualizations, Age (10 years old) has a small positive influence on increasing diabetes risk.\n",
    "\n",
    "\n",
    "Generally speaking,\n",
    "\n",
    "| Method | Advantages | Disadvantages |\n",
    "|--------|------------|--------------|\n",
    "| **LIME** (Local Interpretable Model-agnostic Explanations) | - Model-agnostic and works with any black-box model.  <br> - Provides human-interpretable explanations.  <br> - Faster computation compared to SHAP.  <br> - Can be used with both tabular and non-tabular data (e.g., images, text). | - Relies on surrogate models, which may not always faithfully represent the actual model's decision boundary. <br> - Sensitive to sampling and kernel settings. <br> - Explanations can vary between runs due to random sampling. <br> - May struggle with complex interactions between features. |\n",
    "| **SHAP** (SHapley Additive exPlanations) | - Based on solid game-theoretic foundations, ensuring consistency and fairness. <br> - Provides global and local explanations. <br> - More stable and reliable explanations than LIME. <br> - Captures feature interactions effectively. | - Computationally expensive, especially for complex models. <br> - Requires a large number of model evaluations. <br> - Kernel SHAP (model-agnostic version) can be slow on large datasets. <br> - Difficult to interpret when many features are involved. |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
