{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrated Gradients for Image Models\n",
    "\n",
    "Integrated Gradients(IG) are versatile in that they are model-agnostic and can be used as explainability tool for neural network models such as CNNs that use images as inputs. In this notebook, we shall apply IG for two pretrained DNN architectures - one for a pretrained Resnet and another for a x-ray classification image.\n",
    "\n",
    "\n",
    "## **1. Load a pretrained CNN model**\n",
    "\n",
    "\n",
    "- Let's use a pretrained Resnet50 model that was originally trained on ImageNet.\n",
    "\n",
    "- We shall load the pretrained weights and apply the necessary image transformations (resize, crop, normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import urllib.request\n",
    "from captum.attr import IntegratedGradients, NoiseTunnel\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from captum.attr import visualization as viz\n",
    "\n",
    "# First, we load pre-trained ResNet50\n",
    "weights = ResNet50_Weights.IMAGENET1K_V2\n",
    "model = resnet50(weights=weights)\n",
    "\n",
    "print(model.conv1.weight.shape)\n",
    "\n",
    "\n",
    "preprocess = weights.transforms()\n",
    "\n",
    "# Load test image\n",
    "img = Image.open(\"data/img-1.jpg\")\n",
    "plt.imshow(img)\n",
    "img_transformed = preprocess(img)\n",
    "input_tensor = img_transformed.unsqueeze(0)\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Store unnormalized input for IG\n",
    "raw_input_tensor = transforms.Compose([\n",
    "    transforms.Resize(232),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "])(img).unsqueeze(0)\n",
    "\n",
    "\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# on my GPU, OOM error occurs, so I will use CPU\n",
    "#device = torch.device(\"cpu\")\n",
    "input_batch = input_tensor.to(device)\n",
    "raw_input_tensor = raw_input_tensor.to(device)\n",
    "model.to(device)\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "\n",
    "# Get prediction\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "_, indices = torch.sort(output, descending=True)\n",
    "\n",
    "# Download ImageNet class labels\n",
    "url, filename = (\"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\", \"imagenet_classes.txt\")\n",
    "try:\n",
    "    urllib.URLopener().retrieve(url, filename)\n",
    "except:\n",
    "    urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "# Read the categories from the file\n",
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]\n",
    "\n",
    "# Get the top predicted class index\n",
    "predicted_class_idx = indices[0][0].item()\n",
    "\n",
    "# Display the predicted class name and its probability\n",
    "print(f\"Prediction: {categories[predicted_class_idx]} with probability: {probabilities[predicted_class_idx].item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Compute the Integrated Gradients based feature attribution**\n",
    "\n",
    "We compute integrated gradients for n=200 steps for model prediction on this image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Computing integrated gradients...\")\n",
    "# Integrated Gradients\n",
    "ig = IntegratedGradients(model)\n",
    "attr, _ = ig.attribute(raw_input_tensor, target=indices[0][0], n_steps=200, internal_batch_size=3,return_convergence_delta=True)\n",
    "# default_cmap = LinearSegmentedColormap.from_list('custom blue', \n",
    "#                                                  [(0, '#ffffff'),\n",
    "#                                                   (0.25, '#000000'),\n",
    "#                                                   (1, '#000000')], N=256)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "default_cmap = plt.get_cmap('hot')\n",
    "\n",
    "\n",
    "_ = viz.visualize_image_attr(np.transpose(attr.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                             np.transpose(img_transformed.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                             method='blended_heat_map',\n",
    "                             cmap=default_cmap,\n",
    "                             show_colorbar=True,\n",
    "                             sign='positive',\n",
    "                             outlier_perc=1)\n",
    "\n",
    "del attr\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The figure above shows the IG attributions for the model predictions on the car image. However, notice that the attributions are rather noisy and are barely discernable.\n",
    "\n",
    "- In order to obtain a smoother visualization of the attributions of the IG, here, we repeat the computation of IG across multiple noisy versions of the input image and subsequently smoothen across the samples (using mean-squared attributions). This method is implemented in Captum as the  `NoiseTunnel()` functionality.\n",
    "\n",
    "- This helps reduce sensitivity to minor pixel changes and enhances generalization in feature attribution.\n",
    "\n",
    "- The noise-smoothed IG results in a less noisy and more stable visualization.\n",
    "\n",
    "\n",
    "## **3. Enhanced Visualization of Integrated Gradients**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig = IntegratedGradients(model)\n",
    "\n",
    "# Convert input tensor to grayscale\n",
    "input_tensor_gray = transforms.Grayscale()(input_tensor)\n",
    "\n",
    "# Convert grayscale tensor back to 3 channels\n",
    "input_tensor_rgb = input_tensor_gray.repeat(1, 3, 1, 1).to(device)  # Ensure tensor is on the same device as the model\n",
    "\n",
    "noise_tunnel = NoiseTunnel(ig)\n",
    "\n",
    "# Use valid class index for target\n",
    "valid_class_idx = output.argmax(dim=1).item()\n",
    "\n",
    "\n",
    "# Reduce nt_samples and n_steps to avoid memory overload\n",
    "attributions_ig_nt = noise_tunnel.attribute(input_tensor_rgb, nt_samples=5,nt_samples_batch_size=2, nt_type='smoothgrad_sq', target=valid_class_idx, n_steps=50)\n",
    "_ = viz.visualize_image_attr_multiple(np.transpose(attributions_ig_nt.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                                      np.transpose(img_transformed.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                                      [\"original_image\", \"blended_heat_map\"],\n",
    "                                      [\"all\", \"positive\"],\n",
    "                                      cmap=default_cmap,\n",
    "                                      show_colorbar=True)\n",
    "\n",
    "plt.suptitle('Integrated Gradients with Noise Tunnel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The above is the updated IG attribution visualization using `NoiseTunnel()` approach. We see that the model is focusing primarily on the shape and key elements of the car, rather than the background.\n",
    "\n",
    "- Since IG + NoiseTunnel averages attributions over multiple noise-perturbed versions, it ensures that the explanation is more reliable than single-instance IG.\n",
    "\n",
    "- This explains why certain car features (wheels, headlights, side windows) are dominant in the attributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchxrayvision as xrv\n",
    "from PIL import Image\n",
    "from captum.attr import IntegratedGradients, NoiseTunnel, visualization as viz\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and store original image before processing\n",
    "original_img = Image.open(\"data/xray.jpg\").convert('L')  # Convert to grayscale\n",
    "original_img_resized = original_img.resize((224, 224))  # Resize for visualization\n",
    "original_img_np = np.array(original_img_resized)  # Convert to NumPy array\n",
    "\n",
    "# Normalize the image if needed\n",
    "img = np.array(original_img_resized)\n",
    "if img.max() > 1.0:\n",
    "    img = xrv.datasets.normalize(img, 255)\n",
    "\n",
    "# Ensure correct shape for model input\n",
    "if img.ndim == 2:\n",
    "    img = img[None, ...]  # Shape becomes (1, 224, 224)\n",
    "\n",
    "# Apply X-Ray resizer transformation\n",
    "transform = torchvision.transforms.Compose([xrv.datasets.XRayResizer(224)])\n",
    "img_transformed = transform(img)\n",
    "img_transformed = torch.from_numpy(img_transformed).float()\n",
    "\n",
    "# Ensure correct channel format\n",
    "if img_transformed.shape[0] == 3:  \n",
    "    img_transformed = img_transformed[0].unsqueeze(0)  # Convert (3, 224, 224) â†’ (1, 224, 224)\n",
    "\n",
    "# Ensure batch dimension for the model\n",
    "img_transformed = img_transformed.unsqueeze(0)  # Shape: (1, 1, 224, 224)\n",
    "\n",
    "# Load model\n",
    "model = xrv.models.DenseNet(weights=\"densenet121-res224-all\")\n",
    "model.eval()\n",
    "\n",
    "# Predict\n",
    "outputs = model(img_transformed)\n",
    "\n",
    "# Display predictions\n",
    "print(dict(zip(model.pathologies, outputs[0].detach().numpy())))\n",
    "# Top 3 predicted pathologies\n",
    "predicted_pathology = model.pathologies[outputs.argmax(dim=1).item()]\n",
    "print(f'Predicted Pathology: {predicted_pathology}')\n",
    "\n",
    "# Integrated Gradients & Noise Tunnel\n",
    "ig = IntegratedGradients(model)\n",
    "noise_tunnel = NoiseTunnel(ig)\n",
    "\n",
    "# default_cmap = LinearSegmentedColormap.from_list('custom blue', \n",
    "#                                                  [(0, '#ffffff'),\n",
    "#                                                   (0.25, '#000000'),\n",
    "#                                                   (1, '#000000')], N=256)\n",
    "\n",
    "default_cmap = plt.get_cmap('hot')\n",
    "\n",
    "# Reduce `n_steps` and `nt_samples` to prevent crashes\n",
    "attributions_ig_nt = noise_tunnel.attribute(\n",
    "    img_transformed,\n",
    "    nt_samples=5,  # Reduced to avoid memory overload\n",
    "    nt_type='smoothgrad_sq',\n",
    "    nt_samples_batch_size=2,\n",
    "    target=outputs.argmax(dim=1).item(),\n",
    "    n_steps=50  # Reduced steps\n",
    ")\n",
    "\n",
    "# Ensure attributions have the correct shape\n",
    "attr = attributions_ig_nt.squeeze(0).cpu().detach().numpy()  # Remove batch dimension\n",
    "attr = np.transpose(attr, (1, 2, 0))  # Ensure shape is (224, 224, 1)\n",
    "\n",
    "# Convert original grayscale image to RGB for visualization\n",
    "original_img_np = np.stack([original_img_np] * 3, axis=-1)  # Convert grayscale to RGB (224, 224, 3)\n",
    "\n",
    "# Visualization with the original unprocessed image\n",
    "_ = viz.visualize_image_attr_multiple(\n",
    "    attr,\n",
    "    original_img_np,  # Use the original image before any processing\n",
    "    [\"original_image\", \"blended_heat_map\"],\n",
    "    [\"all\", \"positive\"],\n",
    "    cmap=default_cmap,\n",
    "    show_colorbar=True\n",
    ")\n",
    "\n",
    "plt.suptitle(f'Integrated Gradients with Noise Tunnel for {predicted_pathology}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### What is Pleural Effusion?\n",
    "\n",
    "Pleural effusion is the abnormal accumulation of fluid within the pleural space, the thin cavity between the pleural layers surrounding the lungs. Pleural effusions can arise from various etiologies, ranging from heart failure and pneumonia to malignancies, such as lung cancer, and systemic inflammatory disorders, such as lupus.\n",
    "\n",
    "**Observations**\n",
    "\n",
    "-\tThe highlighted regions (darkest areas) are in the lower lung fields.\n",
    "-\tThis aligns with common signs of pleural effusion, where fluid often accumulates in the lower lobes.\n",
    "-\tThe attributions are diffused, suggesting that the model relies on multiple areas rather than a single dominant feature.\n",
    "-\tThe spinal region and upper lung zones have minimal attributions, meaning the model is not relying on irrelevant regions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = Image.open(\"data/Pleural Effusion.png\")\n",
    "plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
